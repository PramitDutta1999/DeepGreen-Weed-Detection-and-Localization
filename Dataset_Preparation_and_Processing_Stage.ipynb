{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mount and Import"
      ],
      "metadata": {
        "id": "a7FimVOHctnU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIzhRcJFKl_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f362395f-a980-4107-bea0-5333e5b10519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx2_bDt3Kunj"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "zip_path = '/content/drive/MyDrive/MV Project/crop & weed.zip'\n",
        "extract_path = '/content/dataset'\n",
        "\n",
        "with ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKWUAwl9MHL6"
      },
      "source": [
        "# Raw Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjO8-tPrSQv7",
        "outputId": "1fbb5db6-7043-4d75-de01-bd954ff66e54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 'weed' instances: 7442\n",
            "Total 'crop' instances: 411\n",
            "Total objects: 7853\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "annotation_dir = \"/content/dataset/Ronin_OPEN_DB/annotations\"  # path\n",
        "\n",
        "# Counters\n",
        "weed_count = 0\n",
        "crop_count = 0\n",
        "\n",
        "# Loop\n",
        "for xml_file in os.listdir(annotation_dir):\n",
        "\n",
        "    if xml_file.endswith(\".xml\"):\n",
        "        file_path = os.path.join(annotation_dir, xml_file)\n",
        "\n",
        "        try:\n",
        "            tree = ET.parse(file_path)\n",
        "            root = tree.getroot()\n",
        "\n",
        "            # Count\n",
        "            for obj in root.findall(\"object\"):\n",
        "                class_name = obj.find(\"name\").text\n",
        "\n",
        "                if class_name == \"weed\":\n",
        "                    weed_count += 1\n",
        "\n",
        "                elif class_name == \"crop\":\n",
        "                    crop_count += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {xml_file}: {e}\")\n",
        "\n",
        "# Print\n",
        "print(f\"Total 'weed' instances: {weed_count}\")\n",
        "print(f\"Total 'crop' instances: {crop_count}\")\n",
        "print(f\"Total objects: {weed_count + crop_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjIysSfGSyCM",
        "outputId": "c78fdecd-5759-4cb7-ffd6-421fdf31383d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 'weed' instances: 7442\n",
            "Total 'crop' instances: 411\n",
            "Total objects: 7853\n",
            "Files with at least one 'weed': 1132\n",
            "Files with at least one 'crop': 103\n",
            "Total XML files processed: 1176\n"
          ]
        }
      ],
      "source": [
        "annotation_dir = \"/content/dataset/Ronin_OPEN_DB/annotations\"  # path\n",
        "\n",
        "# Counters\n",
        "weed_count = 0\n",
        "crop_count = 0\n",
        "files_with_weed = 0\n",
        "files_with_crop = 0\n",
        "\n",
        "# Loop\n",
        "for xml_file in os.listdir(annotation_dir):\n",
        "\n",
        "    if xml_file.endswith(\".xml\"):\n",
        "        file_path = os.path.join(annotation_dir, xml_file)\n",
        "\n",
        "        try:\n",
        "            tree = ET.parse(file_path)\n",
        "            root = tree.getroot()\n",
        "\n",
        "            # Flags\n",
        "            has_weed = False\n",
        "            has_crop = False\n",
        "\n",
        "            # Count\n",
        "            for obj in root.findall(\"object\"):\n",
        "                class_name = obj.find(\"name\").text.lower()  # Case-insensitive\n",
        "\n",
        "                if class_name == \"weed\":\n",
        "                    weed_count += 1\n",
        "                    has_weed = True\n",
        "\n",
        "                elif class_name == \"crop\":\n",
        "                    crop_count += 1\n",
        "                    has_crop = True\n",
        "\n",
        "            # Update\n",
        "            if has_weed:\n",
        "                files_with_weed += 1\n",
        "\n",
        "            if has_crop:\n",
        "                files_with_crop += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {xml_file}: {e}\")\n",
        "\n",
        "# Print\n",
        "print(f\"Total 'weed' instances: {weed_count}\")\n",
        "print(f\"Total 'crop' instances: {crop_count}\")\n",
        "print(f\"Total objects: {weed_count + crop_count}\")\n",
        "print(f\"Files with at least one 'weed': {files_with_weed}\")\n",
        "print(f\"Files with at least one 'crop': {files_with_crop}\")\n",
        "print(f\"Total XML files processed: {len([f for f in os.listdir(annotation_dir) if f.endswith('.xml')])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdB-d09TLJny",
        "outputId": "a0a7b467-2b68-490d-8f4f-81f4d96ac921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Directories searched:\n",
            "Checked: /content/dataset\n",
            "Checked: /content/dataset/Ronin_OPEN_DB\n",
            "Checked: /content/dataset/Ronin_OPEN_DB/annotations\n",
            "Files found: ['32917.xml', '32556.xml', 'IMG_5965.xml', 'IMG_5976.xml', '32331.xml']\n",
            "Checked: /content/dataset/Ronin_OPEN_DB/raw images\n",
            "Files found: ['34294.jpg', 'IMG_5934.JPG', '32747.jpg', '32502.jpg', 'IMG_6119.JPG']\n"
          ]
        }
      ],
      "source": [
        "# directory\n",
        "start_path = \"/content/dataset\"\n",
        "\n",
        "# Variable to track\n",
        "found = False\n",
        "\n",
        "# Walk through\n",
        "for root, dirs, files in os.walk(start_path):\n",
        "    # Check\n",
        "    xml_files = [f for f in files if f.endswith('.xml')]\n",
        "    jpg_files = [f for f in files if f.endswith('.jpg')]\n",
        "\n",
        "    # find\n",
        "    if xml_files and jpg_files:\n",
        "        directory = os.path.abspath(root)\n",
        "        print(f\"First directory with both XML and JPG found: {directory}\")\n",
        "        print(f\"Some XML files: {xml_files[:3]}\")  # Show up to 3 XML files\n",
        "        print(f\"Some JPG files: {jpg_files[:3]}\")  # Show up to 3 JPG files\n",
        "        found = True\n",
        "        break  # Stop\n",
        "\n",
        "if not found:\n",
        "    # show\n",
        "    print(\"\\nDirectories searched:\")\n",
        "    for root, dirs, files in os.walk(start_path):\n",
        "        print(f\"Checked: {root}\")\n",
        "        if files:\n",
        "            print(f\"Files found: {files[:5]}\")  # Show up to 5 files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Dataset"
      ],
      "metadata": {
        "id": "kNnsPR4H3S6u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-SW9B-WLwRT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "# Define\n",
        "base_path = \"/content/dataset/Ronin_OPEN_DB\"\n",
        "image_dir = os.path.join(base_path, \"raw images\")\n",
        "annotation_dir = os.path.join(base_path, \"annotations\")\n",
        "output_dir = \"/content/yolo_format_dataset\"\n",
        "\n",
        "# Class mapping\n",
        "class_map = {\n",
        "    \"weed\": 0,\n",
        "    \"crop\": 1\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert XML to YOLO format\n",
        "def xml_to_yolo(xml_path):\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "    size = root.find('size')\n",
        "    img_width = float(size.find('width').text)\n",
        "    img_height = float(size.find('height').text)\n",
        "    yolo_lines = []\n",
        "\n",
        "    for obj in root.findall('object'):\n",
        "        class_name = obj.find('name').text\n",
        "        try:\n",
        "            class_id = class_map[class_name]\n",
        "        except KeyError:\n",
        "            print(f\"Warning: Class '{class_name}' not in class_map. Skipping object in {xml_path}\")\n",
        "            continue\n",
        "\n",
        "        bbox = obj.find('bndbox')\n",
        "        xmin = float(bbox.find('xmin').text)\n",
        "        ymin = float(bbox.find('ymin').text)\n",
        "        xmax = float(bbox.find('xmax').text)\n",
        "        ymax = float(bbox.find('ymax').text)\n",
        "\n",
        "        x_center = (xmin + xmax) / 2 / img_width\n",
        "        y_center = (ymin + ymax) / 2 / img_height\n",
        "        width = (xmax - xmin) / img_width\n",
        "        height = (ymax - ymin) / img_height\n",
        "\n",
        "        yolo_lines.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
        "\n",
        "    return \"\\n\".join(yolo_lines)"
      ],
      "metadata": {
        "id": "WJdn3v8j3cUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Prepare\n",
        "def prepare_stratified_dataset(image_dir, annotation_dir, output_dir):\n",
        "    def create_dataset_structure():\n",
        "        dirs = {\n",
        "            'train_images': os.path.join(output_dir, 'images/train'),\n",
        "            'validation_images': os.path.join(output_dir, 'images/validation'),\n",
        "            'test_images': os.path.join(output_dir, 'images/test'),\n",
        "            'train_labels': os.path.join(output_dir, 'labels/train'),\n",
        "            'validation_labels': os.path.join(output_dir, 'labels/validation'),\n",
        "            'test_labels': os.path.join(output_dir, 'labels/test'),\n",
        "        }\n",
        "        for d in dirs.values():\n",
        "            os.makedirs(d, exist_ok=True)\n",
        "        return dirs\n",
        "\n",
        "    # Group\n",
        "    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg'))]\n",
        "    groups = {'weed_only': [], 'crop_only': [], 'both': []}\n",
        "\n",
        "    for img_file in image_files:\n",
        "        base = os.path.splitext(img_file)[0]\n",
        "        ann_file = os.path.join(annotation_dir, base + '.xml')\n",
        "        if os.path.exists(ann_file):\n",
        "            yolo_txt = xml_to_yolo(ann_file)\n",
        "            classes = set(line.split()[0] for line in yolo_txt.strip().split('\\n') if line)\n",
        "            if classes == {'0'}:\n",
        "                groups['weed_only'].append((img_file, yolo_txt))\n",
        "            elif classes == {'1'}:\n",
        "                groups['crop_only'].append((img_file, yolo_txt))\n",
        "            elif classes == {'0', '1'} or classes == {'1', '0'}:\n",
        "                groups['both'].append((img_file, yolo_txt))\n",
        "\n",
        "    def stratified_split(data, train_ratio=0.9, val_ratio=0.05):\n",
        "        np.random.shuffle(data)\n",
        "        total = len(data)\n",
        "        train_end = int(total * train_ratio)\n",
        "        val_end = train_end + int(total * val_ratio)\n",
        "        return data[:train_end], data[train_end:val_end], data[val_end:]\n",
        "\n",
        "    # Apply splitting\n",
        "    train_data, val_data, test_data = [], [], []\n",
        "    for group in groups.values():\n",
        "        tr, va, te = stratified_split(group)\n",
        "        train_data += tr\n",
        "        val_data += va\n",
        "        test_data += te\n",
        "\n",
        "    dirs = create_dataset_structure()\n",
        "\n",
        "    def copy_data(data, img_dest, label_dest):\n",
        "        for img_file, yolo_txt in data:\n",
        "            base = os.path.splitext(img_file)[0]\n",
        "            src_img_path = os.path.join(image_dir, img_file)\n",
        "            dst_img_path = os.path.join(img_dest, img_file)\n",
        "            shutil.copy(src_img_path, dst_img_path)\n",
        "\n",
        "            label_path = os.path.join(label_dest, base + '.txt')\n",
        "            with open(label_path, 'w') as f:\n",
        "                f.write(yolo_txt)\n",
        "\n",
        "    copy_data(train_data, dirs['train_images'], dirs['train_labels'])\n",
        "    copy_data(val_data, dirs['validation_images'], dirs['validation_labels'])\n",
        "    copy_data(test_data, dirs['test_images'], dirs['test_labels'])\n",
        "\n",
        "    # data.yaml\n",
        "    data_yaml = f\"\"\"\n",
        "path: {output_dir}\n",
        "train: images/train\n",
        "val: images/validation\n",
        "test: images/test\n",
        "names:\n",
        "  0: weed\n",
        "  1: crop\n",
        "\"\"\"\n",
        "    yaml_path = os.path.join(output_dir, \"data.yaml\")\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        f.write(data_yaml.strip())\n",
        "\n",
        "    return dirs"
      ],
      "metadata": {
        "id": "iD9e_YLH3iA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepare_stratified_dataset(\n",
        "    image_dir=\"/content/dataset/Ronin_OPEN_DB/raw images\",\n",
        "    annotation_dir=\"/content/dataset/Ronin_OPEN_DB/annotations\",\n",
        "    output_dir=\"/content/yolo_format_dataset\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pfuXRG732hu",
        "outputId": "3db308e0-9a7c-403e-b0d7-3196d01376e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train_images': '/content/yolo_format_dataset/images/train',\n",
              " 'validation_images': '/content/yolo_format_dataset/images/validation',\n",
              " 'test_images': '/content/yolo_format_dataset/images/test',\n",
              " 'train_labels': '/content/yolo_format_dataset/labels/train',\n",
              " 'validation_labels': '/content/yolo_format_dataset/labels/validation',\n",
              " 'test_labels': '/content/yolo_format_dataset/labels/test'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define\n",
        "output_dir = \"/content/yolo_format_dataset\"\n",
        "zip_path = \"/content/yolo_format_dataset.zip\"\n",
        "\n",
        "# Create zip\n",
        "def create_zip():\n",
        "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, _, files in os.walk(output_dir):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, os.path.dirname(output_dir))  # preserve yolo_format_dataset folder\n",
        "                zipf.write(file_path, arcname)\n",
        "    return zip_path\n",
        "\n",
        "\n",
        "zip_file = create_zip()\n",
        "print(f\"Zip created: {zip_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7_1TOQR4Y1f",
        "outputId": "72bcb0f9-f6ca-4fa8-a6e9-eaaf913a58ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip created: /content/yolo_format_dataset.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def check_yolo_pairs(image_dir, label_dir):\n",
        "    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    label_files = [f for f in os.listdir(label_dir) if f.endswith('.txt')]\n",
        "\n",
        "    image_basenames = set(os.path.splitext(f)[0] for f in image_files)\n",
        "    label_basenames = set(os.path.splitext(f)[0] for f in label_files)\n",
        "\n",
        "    missing_labels = image_basenames - label_basenames\n",
        "    missing_images = label_basenames - image_basenames\n",
        "\n",
        "    print(f\"Total images: {len(image_files)}\")\n",
        "    print(f\"Total labels: {len(label_files)}\")\n",
        "    print(f\"Images with NO matching label: {len(missing_labels)}\")\n",
        "    print(f\"Labels with NO matching image: {len(missing_images)}\")\n",
        "\n",
        "    if missing_labels:\n",
        "        print(\"\\nImages without labels:\")\n",
        "        for f in sorted(missing_labels):\n",
        "            print(f\"{f}.jpg\")\n",
        "\n",
        "    if missing_images:\n",
        "        print(\"\\nLabels without images:\")\n",
        "        for f in sorted(missing_images):\n",
        "            print(f\"{f}.txt\")\n",
        "\n",
        "# Run the checks\n",
        "check_yolo_pairs('/content/yolo_format_dataset/images/train', '/content/yolo_format_dataset/labels/train')\n",
        "check_yolo_pairs('/content/yolo_format_dataset/images/validation', '/content/yolo_format_dataset/labels/validation')\n",
        "check_yolo_pairs('/content/yolo_format_dataset/images/test', '/content/yolo_format_dataset/labels/test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7vH0F0T4ngH",
        "outputId": "37bf0a0c-9dde-479b-8a07-c601bf2947ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 1057\n",
            "Total labels: 1057\n",
            "Images with NO matching label: 0\n",
            "Labels with NO matching image: 0\n",
            "Total images: 57\n",
            "Total labels: 57\n",
            "Images with NO matching label: 0\n",
            "Labels with NO matching image: 0\n",
            "Total images: 62\n",
            "Total labels: 62\n",
            "Images with NO matching label: 0\n",
            "Labels with NO matching image: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_weed_and_crop(file_path):\n",
        "\n",
        "    # Open\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            lines = file.readlines()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "    # Extract\n",
        "    class_ids = []\n",
        "\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "\n",
        "        if parts:\n",
        "            class_id = int(parts[0])  # Convert\n",
        "            class_ids.append(class_id)\n",
        "\n",
        "    # Check\n",
        "    has_weed = 0 in class_ids\n",
        "    has_crop = 1 in class_ids\n",
        "    return has_weed and has_crop"
      ],
      "metadata": {
        "id": "j377hyJA6qvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_three_folders_for_weed_and_crop(folder1_path, folder2_path, folder3_path):\n",
        "\n",
        "    # Function to process a single folder\n",
        "    def process_folder(folder_path):\n",
        "        txt_files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
        "        both_present = 0\n",
        "        either_present = 0\n",
        "\n",
        "        for txt_file in txt_files:\n",
        "            file_path = os.path.join(folder_path, txt_file)\n",
        "            result = check_weed_and_crop(file_path)\n",
        "\n",
        "            if result:\n",
        "                both_present += 1\n",
        "            else:\n",
        "                either_present += 1\n",
        "\n",
        "        total_files = both_present + either_present\n",
        "        return both_present, either_present, total_files\n",
        "\n",
        "    # Folder 1\n",
        "    print(f\"\\nProcessing Folder 1: {folder1_path}\")\n",
        "    both1, either1, total1 = process_folder(folder1_path)\n",
        "    print(f\"Files with both 'weed' and 'crop': {both1}\")\n",
        "    print(f\"Files with either 'weed' or 'crop' or neither: {either1}\")\n",
        "    print(f\"Total files in Folder 1: {total1}\")\n",
        "\n",
        "    # Folder 2\n",
        "    print(f\"\\nProcessing Folder 2: {folder2_path}\")\n",
        "    both2, either2, total2 = process_folder(folder2_path)\n",
        "    print(f\"Files with both 'weed' and 'crop': {both2}\")\n",
        "    print(f\"Files with either 'weed' or 'crop' or neither: {either2}\")\n",
        "    print(f\"Total files in Folder 2: {total2}\")\n",
        "\n",
        "    # Folder 3\n",
        "    print(f\"\\nProcessing Folder 3: {folder3_path}\")\n",
        "    both3, either3, total3 = process_folder(folder3_path)\n",
        "    print(f\"Files with both 'weed' and 'crop': {both3}\")\n",
        "    print(f\"Files with either 'weed' or 'crop' or neither: {either3}\")\n",
        "    print(f\"Total files in Folder 3: {total3}\")\n",
        "\n",
        "    # Grand totals\n",
        "    grand_both = both1 + both2 + both3\n",
        "    grand_either = either1 + either2 + either3\n",
        "    grand_total = total1 + total2 + total3\n",
        "\n",
        "    print(f\"\\nGrand Totals Across All Folders:\")\n",
        "    print(f\"Total files with both 'weed' and 'crop': {grand_both}\")\n",
        "    print(f\"Total files with either 'weed' or 'crop' or neither: {grand_either}\")\n",
        "    print(f\"Total files processed: {grand_total}\")"
      ],
      "metadata": {
        "id": "lgMMb1406ru3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# usage\n",
        "check_three_folders_for_weed_and_crop(\n",
        "    '/content/yolo_format_dataset/labels/train',\n",
        "    '/content/yolo_format_dataset/labels/validation',\n",
        "    '/content/yolo_format_dataset/labels/test'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAEqO2k65S-x",
        "outputId": "75553888-ec97-463e-a8a4-b82b9ddf7393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Folder 1: /content/yolo_format_dataset/labels/train\n",
            "Files with both 'weed' and 'crop': 53\n",
            "Files with either 'weed' or 'crop' or neither: 1004\n",
            "Total files in Folder 1: 1057\n",
            "\n",
            "Processing Folder 2: /content/yolo_format_dataset/labels/validation\n",
            "Files with both 'weed' and 'crop': 2\n",
            "Files with either 'weed' or 'crop' or neither: 55\n",
            "Total files in Folder 2: 57\n",
            "\n",
            "Processing Folder 3: /content/yolo_format_dataset/labels/test\n",
            "Files with both 'weed' and 'crop': 4\n",
            "Files with either 'weed' or 'crop' or neither: 58\n",
            "Total files in Folder 3: 62\n",
            "\n",
            "Grand Totals Across All Folders:\n",
            "Total files with both 'weed' and 'crop': 59\n",
            "Total files with either 'weed' or 'crop' or neither: 1117\n",
            "Total files processed: 1176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move to Google Drive\n",
        "destination_path = \"/content/drive/MyDrive/MV Project/\"\n",
        "shutil.move(zip_file, destination_path)\n",
        "\n",
        "print(f\"Zip file moved to Google Drive: {destination_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lnT8uXe6Pcn",
        "outputId": "8f147021-d5f1-4799-bc65-8e0f257c2d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file moved to Google Drive: /content/drive/MyDrive/MV Project/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKUHgChDNdtH"
      },
      "source": [
        "#Dataset Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKLz-63eNdI6",
        "outputId": "2385ec2b-de98-40d8-a921-7cbc34a7d101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eISIaYdVNoB6"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile('/content/drive/MyDrive/MV Project/yolo_format_dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-igktTULs3cq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Helper function to check contents of a label file\n",
        "def check_weed_and_crop(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    has_weed = any(line.startswith('0') for line in lines)\n",
        "    has_crop = any(line.startswith('1') for line in lines)\n",
        "\n",
        "    if has_weed and has_crop:\n",
        "        return \"both\"\n",
        "    elif has_weed:\n",
        "        return \"weed\"\n",
        "    elif has_crop:\n",
        "        return \"crop\"\n",
        "    else:\n",
        "        return \"neither\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Minimal output version with folder-specific labels\n",
        "def check_three_folders_for_weed_and_crop(folder1_path, folder2_path, folder3_path):\n",
        "    def process_folder(folder_path):\n",
        "        txt_files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
        "        only_weed = 0\n",
        "        only_crop = 0\n",
        "        both = 0\n",
        "\n",
        "        for txt_file in txt_files:\n",
        "            file_path = os.path.join(folder_path, txt_file)\n",
        "            label_type = check_weed_and_crop(file_path).strip()\n",
        "            if label_type == \"weed\":\n",
        "                only_weed += 1\n",
        "            elif label_type == \"crop\":\n",
        "                only_crop += 1\n",
        "            elif label_type == \"both\":\n",
        "                both += 1\n",
        "\n",
        "        total = only_weed + only_crop + both\n",
        "        return only_weed, only_crop, both, total\n",
        "\n",
        "    # Folder 1\n",
        "    w1, c1, b1, t1 = process_folder(folder1_path)\n",
        "    print(f\"Folder 1: Weed = {w1}, Crop = {c1}, Both = {b1}, Total = {t1}\")\n",
        "\n",
        "    # Folder 2\n",
        "    w2, c2, b2, t2 = process_folder(folder2_path)\n",
        "    print(f\"Folder 2: Weed = {w2}, Crop = {c2}, Both = {b2}, Total = {t2}\")\n",
        "\n",
        "    # Folder 3\n",
        "    w3, c3, b3, t3 = process_folder(folder3_path)\n",
        "    print(f\"Folder 3: Weed = {w3}, Crop = {c3}, Both = {b3}, Total = {t3}\")\n",
        "\n",
        "    # Grand totals\n",
        "    total_weed = w1 + w2 + w3\n",
        "    total_crop = c1 + c2 + c3\n",
        "    total_both = b1 + b2 + b3\n",
        "    grand_total = t1 + t2 + t3\n",
        "\n",
        "    print(f\"Grand Total: Weed = {total_weed}, Crop = {total_crop}, Both = {total_both}, Total = {grand_total}\")"
      ],
      "metadata": {
        "id": "wh7I7ibMq6Fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# usage\n",
        "check_three_folders_for_weed_and_crop(\n",
        "    '/content/yolo_format_dataset/labels/train',\n",
        "    '/content/yolo_format_dataset/labels/validation',\n",
        "    '/content/yolo_format_dataset/labels/test'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yEX-NvSFJwR",
        "outputId": "aba5be7d-637a-4346-cda7-8e5f44e702d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder 1: Weed = 965, Crop = 39, Both = 53, Total = 1057\n",
            "Folder 2: Weed = 53, Crop = 2, Both = 2, Total = 57\n",
            "Folder 3: Weed = 55, Crop = 3, Both = 4, Total = 62\n",
            "Grand Total: Weed = 1073, Crop = 44, Both = 59, Total = 1176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AQXLzIkRbAk"
      },
      "outputs": [],
      "source": [
        "!pip install -q albumentations opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmcB_E-bU_TT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import albumentations as A\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O57KvI7EU9eL"
      },
      "outputs": [],
      "source": [
        "# Define paths\n",
        "BASE_PATH = \"/content/yolo_format_dataset\"\n",
        "SPLITS = [\"train\", \"validation\", \"test\"]\n",
        "CLASS_NAMES = {0: 'weed', 1: 'crop'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bALjLoDQVjR3"
      },
      "outputs": [],
      "source": [
        "# Augmentation configs (except zoom)\n",
        "AUGMENTATIONS = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomRotate90(p=0.5),\n",
        "    A.Rotate(limit=30, p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.HueSaturationValue(p=0.5),\n",
        "    A.MotionBlur(p=0.2),\n",
        "    A.Affine(shear={\"x\": 20, \"y\": 20}, p=0.3)\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNKBjN0PX_73"
      },
      "outputs": [],
      "source": [
        "# Global counter for ignored images\n",
        "ignored_images_counter = 0\n",
        "\n",
        "def get_class_type(label_file):\n",
        "    global ignored_images_counter\n",
        "    try:\n",
        "        with open(label_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            classes = set()\n",
        "\n",
        "            for idx, line in enumerate(lines):\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) < 1:\n",
        "                    print(f\"Malformed line in {label_file} at line {idx + 1}: '{line.strip()}'\")\n",
        "                    ignored_images_counter += 1\n",
        "                    return None\n",
        "\n",
        "                cls_str = parts[0]\n",
        "\n",
        "                try:\n",
        "                    cls = int(float(cls_str))  # handles '0.0', '1.0', etc.\n",
        "                except ValueError:\n",
        "                    print(f\"Invalid class label '{cls_str}' in {label_file} at line {idx + 1}\")\n",
        "                    ignored_images_counter += 1\n",
        "                    continue\n",
        "\n",
        "                if cls not in [0, 1]:\n",
        "                    print(f\"Unexpected class '{cls}' in {label_file} at line {idx + 1}\")\n",
        "                    ignored_images_counter += 1\n",
        "                    return None\n",
        "\n",
        "                classes.add(cls)\n",
        "\n",
        "            if classes == {1}:\n",
        "                return 'crop'\n",
        "            elif classes == {0}:\n",
        "                return 'weed'\n",
        "            elif classes == {0, 1}:\n",
        "                return 'both'\n",
        "            else:\n",
        "                print(f\"Unknown class combination in {label_file}: {classes}\")\n",
        "                ignored_images_counter += 1\n",
        "                return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {label_file}: {e}\")\n",
        "        ignored_images_counter += 1\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9f9bEUGYJP-"
      },
      "outputs": [],
      "source": [
        "def apply_augmentation(image_path, label_path, class_type, augment_times, image_dir, label_dir):\n",
        "    image = cv2.imread(image_path)\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    # Load and parse original bounding boxes\n",
        "    with open(label_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    bboxes = []\n",
        "    class_labels = []\n",
        "    for line in lines:\n",
        "        cls, x, y, w, h = map(float, line.strip().split())\n",
        "        x = min(max(x, 0.0), 1.0)\n",
        "        y = min(max(y, 0.0), 1.0)\n",
        "        w = min(max(w, 0.0), 1.0)\n",
        "        h = min(max(h, 0.0), 1.0)\n",
        "        if w > 0 and h > 0:\n",
        "            bboxes.append([x, y, w, h])\n",
        "            class_labels.append(int(cls))\n",
        "\n",
        "    if len(bboxes) == 0:\n",
        "        return  # skip images with no valid bboxes\n",
        "\n",
        "    base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "    for i in range(augment_times):\n",
        "        try:\n",
        "            augmented = AUGMENTATIONS(image=image, bboxes=bboxes, class_labels=class_labels)\n",
        "        except ValueError:\n",
        "            print(f\"[{class_type.upper()}] Skipped]\")\n",
        "            continue\n",
        "\n",
        "        aug_image = augmented['image']\n",
        "        aug_bboxes = augmented['bboxes']\n",
        "        aug_labels = augmented['class_labels']\n",
        "\n",
        "        # Post-clip and validate bboxes\n",
        "        clipped_aug_bboxes = []\n",
        "        clipped_aug_labels = []\n",
        "\n",
        "        for cls, bbox in zip(aug_labels, aug_bboxes):\n",
        "            x, y, w, h = bbox\n",
        "            x = min(max(x, 0.0), 1.0)\n",
        "            y = min(max(y, 0.0), 1.0)\n",
        "            w = min(max(w, 0.0), 1.0)\n",
        "            h = min(max(h, 0.0), 1.0)\n",
        "\n",
        "            if w > 0 and h > 0:\n",
        "                clipped_aug_bboxes.append([x, y, w, h])\n",
        "                clipped_aug_labels.append(cls)\n",
        "\n",
        "        skipped = 0\n",
        "        successful = 0\n",
        "        if len(clipped_aug_bboxes) == 0:\n",
        "            skipped += 1\n",
        "            print(f\"[{class_type.upper()}] Aug {i+1}/{augment_times} for {image_path} — Success: {successful}, Skipped: {skipped}\")\n",
        "            continue\n",
        "        else:\n",
        "          successful += 1\n",
        "\n",
        "        new_image_name = f\"{base_filename}_aug_{i}.jpg\"\n",
        "        new_label_name = f\"{base_filename}_aug_{i}.txt\"\n",
        "        new_image_path = os.path.join(image_dir, new_image_name)\n",
        "        new_label_path = os.path.join(label_dir, new_label_name)\n",
        "\n",
        "\n",
        "        # Save image\n",
        "        cv2.imwrite(new_image_path, aug_image)\n",
        "\n",
        "        # Save label\n",
        "        with open(new_label_path, 'w') as out_f:\n",
        "            for cls, bbox in zip(clipped_aug_labels, clipped_aug_bboxes):\n",
        "                out_f.write(f\"{cls} {' '.join(map(str, bbox))}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Augmenting TRAIN set\")\n",
        "train_img_dir = \"/content/yolo_format_dataset/images/train\"\n",
        "train_lbl_dir = \"/content/yolo_format_dataset/labels/train\"\n",
        "\n",
        "train_imgs = glob.glob(os.path.join(train_img_dir, \"*.jpg\")) + \\\n",
        "             glob.glob(os.path.join(train_img_dir, \"*.JPG\"))\n",
        "for image_path in tqdm(train_imgs, desc=\"Train\"):\n",
        "    label_filename = os.path.basename(image_path).rsplit('.', 1)[0] + \".txt\"\n",
        "    label_path = os.path.join(train_lbl_dir, label_filename)\n",
        "    if not os.path.exists(label_path):\n",
        "        continue\n",
        "    class_type = get_class_type(label_path)\n",
        "    if class_type == 'crop':\n",
        "        apply_augmentation(image_path, label_path, class_type, 25, train_img_dir, train_lbl_dir)\n",
        "    #elif class_type == 'weed':\n",
        "\n",
        "    #elif class_type == 'both':\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rirp42wUHJjY",
        "outputId": "bddbba05-0302-4228-e109-811a73f73908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Augmenting TRAIN set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 1057/1057 [00:21<00:00, 48.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Augmenting VALIDATION set\")\n",
        "val_img_dir = \"/content/yolo_format_dataset/images/validation\"\n",
        "val_lbl_dir = \"/content/yolo_format_dataset/labels/validation\"\n",
        "\n",
        "val_imgs = glob.glob(os.path.join(val_img_dir, \"*.jpg\")) + \\\n",
        "           glob.glob(os.path.join(val_img_dir, \"*.JPG\"))\n",
        "for image_path in tqdm(val_imgs, desc=\"Validation\"):\n",
        "    label_filename = os.path.basename(image_path).rsplit('.', 1)[0] + \".txt\"\n",
        "    label_path = os.path.join(val_lbl_dir, label_filename)\n",
        "    if not os.path.exists(label_path):\n",
        "        continue\n",
        "    class_type = get_class_type(label_path)\n",
        "    if class_type == 'crop':\n",
        "        apply_augmentation(image_path, label_path, class_type, 25, val_img_dir, val_lbl_dir)\n",
        "    # elif class_type == 'weed':\n",
        "\n",
        "    # elif class_type == 'both':\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BoJwP1aHJqC",
        "outputId": "32b3c7e9-2aa6-4bab-87be-61cdb7581e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Augmenting VALIDATION set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 57/57 [00:00<00:00, 95.37it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Augmenting TEST set\")\n",
        "test_img_dir = \"/content/yolo_format_dataset/images/test\"\n",
        "test_lbl_dir = \"/content/yolo_format_dataset/labels/test\"\n",
        "\n",
        "test_imgs = glob.glob(os.path.join(test_img_dir, \"*.jpg\")) + \\\n",
        "            glob.glob(os.path.join(test_img_dir, \"*.JPG\"))\n",
        "'''\n",
        "print(\"Files found:\")\n",
        "for f in test_imgs:\n",
        "    print(os.path.basename(f))\n",
        "'''\n",
        "for image_path in tqdm(test_imgs, desc=\"Test\"):\n",
        "    label_filename = os.path.basename(image_path).rsplit('.', 1)[0] + \".txt\"\n",
        "    label_path = os.path.join(test_lbl_dir, label_filename)\n",
        "    if not os.path.exists(label_path):\n",
        "        continue\n",
        "    class_type = get_class_type(label_path)\n",
        "    if class_type == 'crop':\n",
        "        apply_augmentation(image_path, label_path, class_type, 25, test_img_dir, test_lbl_dir)\n",
        "    # elif class_type == 'weed':\n",
        "\n",
        "    # elif class_type == 'both':\n",
        "    #     apply_augmentation(image_path, label_path, class_type, 7, test_img_dir, test_lbl_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh1E4FwxHJ0Z",
        "outputId": "81f5fe64-2e5f-483e-b283-ae5f641d9fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Augmenting TEST set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 62/62 [00:00<00:00, 90.90it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMsk-3dasA4h",
        "outputId": "782d20cb-4f12-45de-f39d-081f13064e5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "print(ignored_images_counter)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_yolo_pairs(image_dir, label_dir):\n",
        "    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    label_files = [f for f in os.listdir(label_dir) if f.endswith('.txt')]\n",
        "\n",
        "    image_basenames = set(os.path.splitext(f)[0] for f in image_files)\n",
        "    label_basenames = set(os.path.splitext(f)[0] for f in label_files)\n",
        "\n",
        "    missing_labels = image_basenames - label_basenames\n",
        "    missing_images = label_basenames - image_basenames\n",
        "\n",
        "    print(f\"Total images: {len(image_files)}\")\n",
        "    print(f\"Total labels: {len(label_files)}\")\n",
        "    print(f\"Images with NO matching label: {len(missing_labels)}\")\n",
        "    print(f\"Labels with NO matching image: {len(missing_images)}\")\n",
        "\n",
        "    if missing_labels:\n",
        "        print(\"\\nImages without labels:\")\n",
        "        for f in sorted(missing_labels):\n",
        "            print(f\"{f}.jpg\")\n",
        "\n",
        "    if missing_images:\n",
        "        print(\"\\nLabels without images:\")\n",
        "        for f in sorted(missing_images):\n",
        "            print(f\"{f}.txt\")\n",
        "\n",
        "# Run\n",
        "check_yolo_pairs('/content/yolo_format_dataset/images/train', '/content/yolo_format_dataset/labels/train')\n",
        "check_yolo_pairs('/content/yolo_format_dataset/images/validation', '/content/yolo_format_dataset/labels/validation')\n",
        "check_yolo_pairs('/content/yolo_format_dataset/images/test', '/content/yolo_format_dataset/labels/test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocv5oMLZJwrG",
        "outputId": "30edb13f-1ed1-4622-b4ac-66e090f23e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 2032\n",
            "Total labels: 2032\n",
            "Images with NO matching label: 0\n",
            "Labels with NO matching image: 0\n",
            "Total images: 107\n",
            "Total labels: 107\n",
            "Images with NO matching label: 0\n",
            "Labels with NO matching image: 0\n",
            "Total images: 137\n",
            "Total labels: 137\n",
            "Images with NO matching label: 0\n",
            "Labels with NO matching image: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check\n",
        "def check_weed_and_crop(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    has_weed = any(line.startswith('0') for line in lines)\n",
        "    has_crop = any(line.startswith('1') for line in lines)\n",
        "\n",
        "    if has_weed and has_crop:\n",
        "        return \"both\"\n",
        "    elif has_weed:\n",
        "        return \"weed\"\n",
        "    elif has_crop:\n",
        "        return \"crop\"\n",
        "    else:\n",
        "        return \"neither\""
      ],
      "metadata": {
        "id": "4r4D-l-GIWDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_three_folders_for_weed_and_crop(folder1_path, folder2_path, folder3_path):\n",
        "    def process_folder(folder_path):\n",
        "        txt_files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
        "        only_weed = 0\n",
        "        only_crop = 0\n",
        "        both = 0\n",
        "\n",
        "        for txt_file in txt_files:\n",
        "            file_path = os.path.join(folder_path, txt_file)\n",
        "            label_type = check_weed_and_crop(file_path).strip()\n",
        "            if label_type == \"weed\":\n",
        "                only_weed += 1\n",
        "            elif label_type == \"crop\":\n",
        "                only_crop += 1\n",
        "            elif label_type == \"both\":\n",
        "                both += 1\n",
        "\n",
        "        total = only_weed + only_crop + both\n",
        "        return only_weed, only_crop, both, total\n",
        "\n",
        "    # Folder 1\n",
        "    w1, c1, b1, t1 = process_folder(folder1_path)\n",
        "    print(f\"Folder 1: Weed = {w1}, Crop = {c1}, Both = {b1}, Total = {t1}\")\n",
        "\n",
        "    # Folder 2\n",
        "    w2, c2, b2, t2 = process_folder(folder2_path)\n",
        "    print(f\"Folder 2: Weed = {w2}, Crop = {c2}, Both = {b2}, Total = {t2}\")\n",
        "\n",
        "    # Folder 3\n",
        "    w3, c3, b3, t3 = process_folder(folder3_path)\n",
        "    print(f\"Folder 3: Weed = {w3}, Crop = {c3}, Both = {b3}, Total = {t3}\")\n",
        "\n",
        "    # Totals\n",
        "    total_weed = w1 + w2 + w3\n",
        "    total_crop = c1 + c2 + c3\n",
        "    total_both = b1 + b2 + b3\n",
        "    grand_total = t1 + t2 + t3\n",
        "\n",
        "    print(f\"Grand Total: Weed = {total_weed}, Crop = {total_crop}, Both = {total_both}, Total = {grand_total}\")"
      ],
      "metadata": {
        "id": "UqMq_obpIWLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJvURfUN37o8",
        "outputId": "8f1f6376-a1aa-4b4e-f377-5b5451713615"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder 1: Weed = 965, Crop = 1014, Both = 53, Total = 2032\n",
            "Folder 2: Weed = 53, Crop = 52, Both = 2, Total = 107\n",
            "Folder 3: Weed = 55, Crop = 78, Both = 4, Total = 137\n",
            "Grand Total: Weed = 1073, Crop = 1144, Both = 59, Total = 2276\n"
          ]
        }
      ],
      "source": [
        "# usage\n",
        "check_three_folders_for_weed_and_crop(\n",
        "    '/content/yolo_format_dataset/labels/train',\n",
        "    '/content/yolo_format_dataset/labels/validation',\n",
        "    '/content/yolo_format_dataset/labels/test'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-2Q94K3iHf7",
        "outputId": "f2c2d195-84d8-4784-c49b-ee7f7fbca693"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip created: /content/yolo_augmented_dataset.zip\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define\n",
        "output_dir = \"/content/yolo_format_dataset\"\n",
        "zip_path = \"/content/yolo_augmented_dataset.zip\"\n",
        "\n",
        "# Create zip\n",
        "def create_zip():\n",
        "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, _, files in os.walk(output_dir):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, os.path.dirname(output_dir))  # preserve yolo_format_dataset folder\n",
        "                zipf.write(file_path, arcname)\n",
        "    return zip_path\n",
        "\n",
        "\n",
        "zip_file = create_zip()\n",
        "print(f\"Zip created: {zip_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epWzQiYO2ykq",
        "outputId": "73c17f38-11d5-4a43-d5c2-bb3bf294f83e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file moved to Google Drive: /content/drive/MyDrive/MV Project/Augmentation\n"
          ]
        }
      ],
      "source": [
        "# Move to Google Drive\n",
        "destination_path = \"/content/drive/MyDrive/MV Project/Augmentation\"\n",
        "shutil.move(zip_file, destination_path)\n",
        "\n",
        "print(f\"Zip file moved to Google Drive: {destination_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Preprocessing\n"
      ],
      "metadata": {
        "id": "BRg1rAPn9NOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShlcC8ce3Gnu",
        "outputId": "4646e24b-1c0a-491b-abad-4deddce3af02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfAdfZRNldZy"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "zip_path = '/content/drive/MyDrive/MV Project/Augmentation/yolo_augmented_dataset.zip'\n",
        "extract_path = '/content/new'\n",
        "\n",
        "with ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q opencv-python\n",
        "!pip install -q albumentations"
      ],
      "metadata": {
        "id": "VZi_Ng88-NQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "-SihSu_G-Ngm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input and output\n",
        "input_img_dir = \"/content/new/yolo_format_dataset/images\"\n",
        "output_img_dir = \"/content/yolo_format_dataset/images\"\n",
        "\n",
        "# Create\n",
        "os.makedirs(output_img_dir, exist_ok=True)\n",
        "\n",
        "# Subfolders\n",
        "subfolders = [\"train\", \"validation\", \"test\"]"
      ],
      "metadata": {
        "id": "IseuFXXL9VNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image processing function\n",
        "def process_image(img):\n",
        "\n",
        "    # Convert to HSV\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    h, s, v = cv2.split(hsv)\n",
        "\n",
        "    # CLAHE on the V channel\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    v_clahe = clahe.apply(v)\n",
        "\n",
        "    # Merge and convert\n",
        "    hsv_clahe = cv2.merge((h, s, v_clahe))\n",
        "    img_clahe = cv2.cvtColor(hsv_clahe, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "    # Sharpening\n",
        "    kernel = np.array([[0, -1, 0],\n",
        "                       [-1, 5, -1],\n",
        "                       [0, -1, 0]])\n",
        "\n",
        "    sharpened = cv2.filter2D(img_clahe, -1, kernel)\n",
        "\n",
        "    return sharpened"
      ],
      "metadata": {
        "id": "Y8AKKkZt97yA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_root = \"/content/new/yolo_format_dataset/images\"\n",
        "dest_root = \"/content/yolo_format_dataset/images\"\n",
        "# Process\n",
        "for subfolder in subfolders:\n",
        "    src_folder = os.path.join(source_root, subfolder)\n",
        "    dst_folder = os.path.join(dest_root, subfolder)\n",
        "    os.makedirs(dst_folder, exist_ok=True)\n",
        "\n",
        "    for filename in os.listdir(src_folder):\n",
        "        if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.JPG')):\n",
        "            src_path = os.path.join(src_folder, filename)\n",
        "            dst_path = os.path.join(dst_folder, filename)\n",
        "\n",
        "            img = cv2.imread(src_path)\n",
        "            if img is not None:\n",
        "                processed_img = process_image(img)\n",
        "                cv2.imwrite(dst_path, processed_img)"
      ],
      "metadata": {
        "id": "qdvHrbEi-dC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define\n",
        "original_root = \"/content/new/yolo_format_dataset/images\"\n",
        "processed_root = \"/content/yolo_format_dataset/images\"\n",
        "subfolders = [\"train\", \"validation\", \"test\"]\n",
        "image_exts = ('.jpg', '.jpeg', '.png', '.JPG')\n",
        "\n",
        "# Function to count\n",
        "def count_images(root, name):\n",
        "    print(f\"\\n{name} IMAGE COUNTS:\")\n",
        "    for sub in subfolders:\n",
        "        subdir = os.path.join(root, sub)\n",
        "        if not os.path.exists(subdir):\n",
        "            print(f\"  {sub}: folder does not exist\")\n",
        "            continue\n",
        "        count = len([f for f in os.listdir(subdir) if f.lower().endswith(image_exts)])\n",
        "        print(f\"  {sub}: {count} images\")\n",
        "\n",
        "# Print\n",
        "count_images(original_root, \"ORIGINAL\")\n",
        "count_images(processed_root, \"PROCESSED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGamDAVR-fsG",
        "outputId": "ef44ab9a-d0bf-4166-f821-c9eda94625ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ORIGINAL IMAGE COUNTS:\n",
            "  train: 2032 images\n",
            "  validation: 107 images\n",
            "  test: 137 images\n",
            "\n",
            "PROCESSED IMAGE COUNTS:\n",
            "  train: 2032 images\n",
            "  validation: 107 images\n",
            "  test: 137 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set paths\n",
        "source_folder = \"/content/new/yolo_format_dataset/labels\"  # Replace with your actual folder\n",
        "source_file = \"/content/new/yolo_format_dataset/data.yaml\"  # Replace with your actual file\n",
        "destination_directory = \"/content/yolo_format_dataset\"\n",
        "\n",
        "# Move folder\n",
        "shutil.move(source_folder, os.path.join(destination_directory, os.path.basename(source_folder)))\n",
        "\n",
        "# Move file\n",
        "shutil.move(source_file, os.path.join(destination_directory, os.path.basename(source_file)))\n",
        "\n",
        "print(f\"Moved '{source_folder}' to '{destination_directory}'\")\n",
        "print(f\"Moved '{source_file}' to '{destination_directory}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwTHdnph-ibu",
        "outputId": "6702f8b9-820d-457f-f050-a1d6d7bef230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moved '/content/new/yolo_format_dataset/labels' to '/content/yolo_format_dataset'\n",
            "Moved '/content/new/yolo_format_dataset/data.yaml' to '/content/yolo_format_dataset'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_to_delete = \"/content/new\"\n",
        "\n",
        "# Delete\n",
        "if os.path.exists(folder_to_delete):\n",
        "    shutil.rmtree(folder_to_delete)\n",
        "    print(f\"Deleted folder: {folder_to_delete}\")\n",
        "else:\n",
        "    print(f\"Folder does not exist: {folder_to_delete}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D64OUSKX-lq3",
        "outputId": "4771d7dc-706d-4bc7-8da3-bf33ae15f0c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted folder: /content/new\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_yolo_pairs(image_dir, label_dir):\n",
        "    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    label_files = [f for f in os.listdir(label_dir) if f.endswith('.txt')]\n",
        "\n",
        "    image_basenames = set(os.path.splitext(f)[0] for f in image_files)\n",
        "    label_basenames = set(os.path.splitext(f)[0] for f in label_files)\n",
        "\n",
        "    missing_labels = image_basenames - label_basenames\n",
        "    missing_images = label_basenames - image_basenames\n",
        "\n",
        "    print(f\"Total images: {len(image_files)}\")\n",
        "    print(f\"Total labels: {len(label_files)}\")\n",
        "    print(f\"Images with NO matching label: {len(missing_labels)}\")\n",
        "    print(f\"Labels with NO matching image: {len(missing_images)}\")\n",
        "\n",
        "    if missing_labels:\n",
        "        print(\"\\nImages without labels:\")\n",
        "        for f in sorted(missing_labels):\n",
        "            print(f\"{f}.jpg\")\n",
        "\n",
        "    if missing_images:\n",
        "        print(\"\\nLabels without images:\")\n",
        "        for f in sorted(missing_images):\n",
        "            print(f\"{f}.txt\")\n",
        "\n",
        "# Run the checks\n",
        "check_yolo_pairs('/content/yolo_format_dataset/images/train', '/content/yolo_format_dataset/labels/train')\n",
        "check_yolo_pairs('/content/yolo_format_dataset/images/validation', '/content/yolo_format_dataset/labels/validation')\n",
        "check_yolo_pairs('/content/yolo_format_dataset/images/test', '/content/yolo_format_dataset/labels/test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x51_yM10_Beg",
        "outputId": "6f43d171-66dc-4311-cc11-3a8d829438a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 2032\n",
            "Total labels: 2032\n",
            "Images with NO matching label: 0\n",
            "Labels with NO matching image: 0\n",
            "Total images: 107\n",
            "Total labels: 107\n",
            "Images with NO matching label: 0\n",
            "Labels with NO matching image: 0\n",
            "Total images: 137\n",
            "Total labels: 137\n",
            "Images with NO matching label: 0\n",
            "Labels with NO matching image: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define\n",
        "output_dir = \"/content/yolo_format_dataset\"\n",
        "zip_path = \"/content/yolo_enhanced.zip\"\n",
        "\n",
        "# Create zip\n",
        "def create_zip():\n",
        "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, _, files in os.walk(output_dir):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, os.path.dirname(output_dir))  # preserve yolo_format_dataset folder\n",
        "                zipf.write(file_path, arcname)\n",
        "    return zip_path\n",
        "\n",
        "zip_file = create_zip()\n",
        "print(f\"Zip created: {zip_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzuA_pCL_FFP",
        "outputId": "12a03fe2-8aa1-44f8-cb68-92930abae8fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip created: /content/yolo_enhanced.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move to Google Drive\n",
        "import shutil\n",
        "zip_path = \"/content/yolo_enhanced.zip\"\n",
        "destination_path = \"/content/drive/MyDrive/MV Project/Enhanced/\"\n",
        "shutil.move(zip_path, destination_path)\n",
        "\n",
        "print(f\"Zip file moved to Google Drive: {destination_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tACZucE9_IQ_",
        "outputId": "ed775df0-2742-40a4-ca9a-8813b92a2ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file moved to Google Drive: /content/drive/MyDrive/MV Project/Enhanced/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_to_delete = \"/content/yolo_format_dataset\"\n",
        "\n",
        "# Delete\n",
        "if os.path.exists(folder_to_delete):\n",
        "    shutil.rmtree(folder_to_delete)\n",
        "    print(f\"Deleted folder: {folder_to_delete}\")\n",
        "else:\n",
        "    print(f\"Folder does not exist: {folder_to_delete}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLmSm30z_Kz3",
        "outputId": "2a1333fc-cb1c-4898-8a67-f7f72cc77c95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted folder: /content/yolo_format_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mm6NzdVmElAG",
        "outputId": "dcd97f0a-f4c7-45bb-ee41-1344ea616610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "zip_path = '/content/drive/MyDrive/MV Project/Enhanced/yolo_enhanced.zip'\n",
        "extract_path = '/content/'\n",
        "\n",
        "with ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ],
      "metadata": {
        "id": "FkS-9RnZ_ccP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define\n",
        "original_root = \"/content/yolo_format_dataset/images\"\n",
        "subfolders = [\"train\", \"validation\", \"test\"]\n",
        "image_exts = ('.jpg', '.jpeg', '.png', '.JPG')\n",
        "\n",
        "# Function to count\n",
        "def count_images(root, name):\n",
        "    print(f\"\\n{name} IMAGE COUNTS:\")\n",
        "    for sub in subfolders:\n",
        "        subdir = os.path.join(root, sub)\n",
        "        if not os.path.exists(subdir):\n",
        "            print(f\"  {sub}: folder does not exist\")\n",
        "            continue\n",
        "        count = len([f for f in os.listdir(subdir) if f.lower().endswith(image_exts)])\n",
        "        print(f\"  {sub}: {count} images\")\n",
        "\n",
        "# Print\n",
        "count_images(original_root, \"ORIGINAL\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0pxTURbDW1y",
        "outputId": "bcc3f1b2-0a1a-491d-ed66-b93e40954f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ORIGINAL IMAGE COUNTS:\n",
            "  train: 2032 images\n",
            "  validation: 107 images\n",
            "  test: 137 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_yolo_pairs(image_dir, label_dir):\n",
        "    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    label_files = [f for f in os.listdir(label_dir) if f.endswith('.txt')]\n",
        "\n",
        "    image_basenames = set(os.path.splitext(f)[0] for f in image_files)\n",
        "    label_basenames = set(os.path.splitext(f)[0] for f in label_files)\n",
        "\n",
        "    missing_labels = image_basenames - label_basenames\n",
        "    missing_images = label_basenames - image_basenames\n",
        "\n",
        "    print(f\"Total images: {len(image_files)}\")\n",
        "    print(f\"Total labels: {len(label_files)}\")\n",
        "    print(f\"Images with NO matching label: {len(missing_labels)}\")\n",
        "    print(f\"Labels with NO matching image: {len(missing_images)}\")\n",
        "\n",
        "    if missing_labels:\n",
        "        print(\"\\nImages without labels:\")\n",
        "        for f in sorted(missing_labels):\n",
        "            print(f\"{f}.jpg\")\n",
        "\n",
        "    if missing_images:\n",
        "        print(\"\\nLabels without images:\")\n",
        "        for f in sorted(missing_images):\n",
        "            print(f\"{f}.txt\")\n",
        "\n",
        "# Run the checks\n",
        "check_yolo_pairs('/content/yolo_format_dataset/images/train', '/content/yolo_format_dataset/labels/train')\n",
        "check_yolo_pairs('/content/yolo_format_dataset/images/validation', '/content/yolo_format_dataset/labels/validation')\n",
        "check_yolo_pairs('/content/yolo_format_dataset/images/test', '/content/yolo_format_dataset/labels/test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcvDVemBClru",
        "outputId": "5c39206d-5426-4e4d-8f51-724cc107300e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 2032\n",
            "Total labels: 2032\n",
            "Images with NO matching label: 0\n",
            "Labels with NO matching image: 0\n",
            "Total images: 107\n",
            "Total labels: 107\n",
            "Images with NO matching label: 0\n",
            "Labels with NO matching image: 0\n",
            "Total images: 137\n",
            "Total labels: 137\n",
            "Images with NO matching label: 0\n",
            "Labels with NO matching image: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check\n",
        "def check_weed_and_crop(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    has_weed = any(line.startswith('0') for line in lines)\n",
        "    has_crop = any(line.startswith('1') for line in lines)\n",
        "\n",
        "    if has_weed and has_crop:\n",
        "        return \"both\"\n",
        "    elif has_weed:\n",
        "        return \"weed\"\n",
        "    elif has_crop:\n",
        "        return \"crop\"\n",
        "    else:\n",
        "        return \"neither\""
      ],
      "metadata": {
        "id": "DF962iI4EYe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_three_folders_for_weed_and_crop(folder1_path, folder2_path, folder3_path):\n",
        "    def process_folder(folder_path):\n",
        "        txt_files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
        "        only_weed = 0\n",
        "        only_crop = 0\n",
        "        both = 0\n",
        "\n",
        "        for txt_file in txt_files:\n",
        "            file_path = os.path.join(folder_path, txt_file)\n",
        "            label_type = check_weed_and_crop(file_path).strip()\n",
        "            if label_type == \"weed\":\n",
        "                only_weed += 1\n",
        "            elif label_type == \"crop\":\n",
        "                only_crop += 1\n",
        "            elif label_type == \"both\":\n",
        "                both += 1\n",
        "\n",
        "        total = only_weed + only_crop + both\n",
        "        return only_weed, only_crop, both, total\n",
        "\n",
        "    # Folder 1\n",
        "    w1, c1, b1, t1 = process_folder(folder1_path)\n",
        "    print(f\"Folder 1: Weed = {w1}, Crop = {c1}, Both = {b1}, Total = {t1}\")\n",
        "\n",
        "    # Folder 2\n",
        "    w2, c2, b2, t2 = process_folder(folder2_path)\n",
        "    print(f\"Folder 2: Weed = {w2}, Crop = {c2}, Both = {b2}, Total = {t2}\")\n",
        "\n",
        "    # Folder 3\n",
        "    w3, c3, b3, t3 = process_folder(folder3_path)\n",
        "    print(f\"Folder 3: Weed = {w3}, Crop = {c3}, Both = {b3}, Total = {t3}\")\n",
        "\n",
        "    # Totals\n",
        "    total_weed = w1 + w2 + w3\n",
        "    total_crop = c1 + c2 + c3\n",
        "    total_both = b1 + b2 + b3\n",
        "    grand_total = t1 + t2 + t3\n",
        "\n",
        "    print(f\"Grand Total: Weed = {total_weed}, Crop = {total_crop}, Both = {total_both}, Total = {grand_total}\")"
      ],
      "metadata": {
        "id": "lQJxqsg-EbEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# usage\n",
        "check_three_folders_for_weed_and_crop(\n",
        "    '/content/yolo_format_dataset/labels/train',\n",
        "    '/content/yolo_format_dataset/labels/validation',\n",
        "    '/content/yolo_format_dataset/labels/test'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBI3f7FjEe_V",
        "outputId": "585b0528-a56a-47a5-8555-2adb85bcd4c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder 1: Weed = 965, Crop = 1014, Both = 53, Total = 2032\n",
            "Folder 2: Weed = 53, Crop = 52, Both = 2, Total = 107\n",
            "Folder 3: Weed = 55, Crop = 78, Both = 4, Total = 137\n",
            "Grand Total: Weed = 1073, Crop = 1144, Both = 59, Total = 2276\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "a7FimVOHctnU",
        "nKWUAwl9MHL6",
        "kNnsPR4H3S6u",
        "eKUHgChDNdtH",
        "BRg1rAPn9NOP"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}